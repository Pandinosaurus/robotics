{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gtbook/robotics/blob/main/S53_duckiebot_sensing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JoW4C_OkOMhe",
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U gtbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "10-snNDwOSuC",
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import math\n",
    "import requests\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "# try:\n",
    "#     import google.colab\n",
    "# except:\n",
    "#     import plotly.io as pio\n",
    "#     pio.renderers.default = \"png\"\n",
    "\n",
    "import gtsam \n",
    "from gtbook import diffdrive\n",
    "from gtbook.html import ROW\n",
    "\n",
    "FIG5 = \"https://raw.githubusercontent.com/gtbook/robotics/main/Figures5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAvx4-UCNzt2"
   },
   "source": [
    "# Robot Vision\n",
    "\n",
    "> A camera is a super-sensor.\n",
    "\n",
    "**This Section is still in draft mode and was released for adventurous spirits (and TAs) only.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div align='center'>\n",
       "        <img src='https://github.com/gtbook/robotics/blob/main/Art/steampunk/S53-Two-wheeled%20Toy%20Robot-02.jpg?raw=1' style='height:256 width:100%'/>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gtbook.display import randomImages\n",
    "from IPython.display import display\n",
    "display(randomImages(5, 3, \"steampunk\", 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cameras\n",
    "\n",
    "> Introduction to cameras.\n",
    "\n",
    "Everyone knows what a camera is these days, and you probably have between 1 and 5 on your phone, depending on what model you have.\n",
    "\n",
    "Historically, a **Camera Obscura**, literally \"dark room\", showed people that focused *upside-down* images can be formed on a surface, provided the light rays coming from outside the room were constricted to a small \"pinhole\". If you have never experienced this in real-life, it is a worthwhile experience to see this with your own eyes. One of the surprising but obvious properties of a camera obscura is that the images *move*: it really is *video obscura*.\n",
    "\n",
    "The question then is how to capture these fleeting images. Da Vinci apparently wrote extensively about the using the camera obscura for drawing, and several 17th century painters may have used it in their painting process, the most famous of them being [Johannes Vermeer](https://en.wikipedia.org/wiki/Johannes_Vermeer).\n",
    "The invention of **photography** (painting with light!) is usually credited to [NiÃ©pce](https://en.wikipedia.org/wiki/Nic%C3%A9phore_Ni%C3%A9pce), who used a light-sensitive material to capture the light around 1825. However, it was his partner [Daguerre](https://en.wikipedia.org/wiki/Louis_Daguerre) who introduced photography to the world on a large scale via his *Daguerreotype* process, released into the public domain in 1839.\n",
    "\n",
    "Since the 1990s, **digital cameras** have replaced cameras based on chemical emulsions, using CCDs (charged-coupled devices) or CMOS sensors as the underlying technology. Both sensor types capture photons in an array of picture elements or **pixels**. We will not discuss in detail how this devices work, but in essence both sensor types count how many photons fall onto each pixel's area over a given time period. Below we discuss the more practical matter of the format in which images come to us, and how they can be used for robot vision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cameras for Robot Vision\n",
    "\n",
    "> Two sensors in one\n",
    "\n",
    "Cameras are amazing devices, and actually pack *two* sensors in one. First, a camera accurately measures the direction to points in space. Second, the 2D images formed on the sensor can be analyzed by computer vision algorithms to recognize objects and analyze the scene in front of the robot. In this section we focus on the mechanics, however, and leave algorithms for Section 5.4.\n",
    "\n",
    "A pinhole by itself is rather amazing, as it renders the entire scene in front entirely *in focus*. However, it has a large drawback, in that it only lets in a tiny amount of light. The solution is to use a **lens**, which *collects* light over a larger diameter and *focuses* the light onto the image sensor. The upshot is that we can collect a lot more light (photons) in the same amount of time. The *downside* is that only part of the scene can be in focus at a given time - a phenomenon that leads to the \"depth of field\" of a camera: the (possibly narrow) area between where objects are tt close or too far to be in focus.\n",
    "\n",
    "The most important properties associated with a digital camera are its *resolution*, typically specified as $W \\times H$ in pixels, its *focal length* $f$, also specified in pixels, and its *field of view* (FOV), typically specified in degrees (horizontal, vertical, or diagonal). The resolution is a property of the *sensor*, whereas focal length and field of view depend on the lens. We will investigate the relationships between these quantities in below, where we talk about te geometry of the camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In essence, we get access to images as multi-dimensional arrays. Expensive CCD cameras have three sensors, one per color channel (**R**ed), **G**reen, and **B**lue), and hence their raw output can be represented as three arrays of numbers that represent light levels in a specific frequency band, roughly corresponding to the same frequency bands that receptors in our eye are sensitive to. However, most cameras now have a *single* CMOS sensor with a color filter on top (called a Bayer pattern), and specialized algorithms that hallucinate three color channels. Actually, most cameras do a great deal more processing to improve the color and lighting; this sometimes gets in the way of algorithms that rely on measuring light exactly, but those are rather rare. In most cases, we are content to forget about all that and simply think of a (color) image as a $H \\times W \\times 3$ array of numbers, where $H$ is the height of the image, and $W$ the width.\n",
    "\n",
    "As an example, below we show an image on the left, taken by the differential drive robot on the right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width=\"100%\" class={cls}>\n",
       "\n",
       "<tr>\n",
       "<td style=\"text-align:left;\"><img src=\"https://raw.githubusercontent.com/gtbook/robotics/main/Figures5/LL_color_1201754063.387872.bmp?raw=1\" alt=\"Outdoor, beaten down path\"></td>\n",
       "<td style=\"text-align:left;\"><img src=\"https://raw.githubusercontent.com/gtbook/robotics/main/Figures5/lagr-robot.jpg?raw=1\" alt=\"LAGR robot\" height=\"359\"></td>\n",
       "</tr></table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_name = \"LL_color_1201754063.387872.bmp\"\n",
    "ROW([f'<img src=\"{FIG5}/{image_name}?raw=1\" alt=\"Outdoor, beaten down path\">',\n",
    "     f'<img src=\"{FIG5}/lagr-robot.jpg?raw=1\" alt=\"LAGR robot\" height=\"359\">'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A python library, the *Python Imaging Library* or PIL provides some basic capabilities to deal with digital images. We can load images using the `PIL.Image` class, examine its dimensions, and create a numpy array view (you can also use `display` in a notebook to show it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolution = 512x384\n",
      "image_data.shape = (384, 512, 3)\n",
      "[82 55 57]\n"
     ]
    }
   ],
   "source": [
    "image = diffdrive.read_image(image_name) # locally: PIL.Image.open(image_name)\n",
    "print(f\"resolution = {image.width}x{image.height}\")\n",
    "image_data = np.asarray(image)\n",
    "print(f\"image_data.shape = {image_data.shape}\")\n",
    "print(image_data[383,511])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the image width and height are $512$ and $384$, respectively. But when we access the array with numpy, the first (slowest changing) dimension is the *height*, followed by the width and then the color dimension. Hence, the numpy array has to be indexed using the $(\\text{row},\\text{column})$ convention, after which you get the RGB value in the array, as shown in the last line of code above.\n",
    "\n",
    "It is customary to use variables $(i,j)$ or $(r,c)$ to index pixels, where the latter is slightly preferred as it emphasizes the *row* and *column* semantics of these *integer* coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Geometry\n",
    "\n",
    "> Points in 3D project to points in 2D.\n",
    "\n",
    "To turn a camera into a useful sensor, we need to describe its operation. \n",
    "We already did so at a superficial level, bit especially the geometry involved needs more detail: exactly what light falls into what pixel?\n",
    "The simplest model for geometric image formation is the **pinhole camera model**. \n",
    "Imagine a three-dimensional, orthogonal coordinate frame centered at center of the lens.\n",
    "Computer vision folks use a very specific camera convention which will make the math easy:\n",
    "- the X-axis points to the *right*;\n",
    "- the Y-axis points *down*; and \n",
    "- the Z-axis points into the scene.\n",
    "\n",
    "When we express 3D points in the scene according to this convention, in a coordinate frame that is attached the the cameras, we speak of specifying an object in *camera coordinates*. For example, a 2 meter tall person, standing 5 meters away, and 3 meters to the left, would have be in between these two 3D coordinates: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feet = gtsam.Point3(-3,1.7,5) # point at the feet of the person, 5 meters in front of camera, 3 meters to the left\n",
    "head = gtsam.Point3(-3,-0.3,5) # point at the top of the head (note, Y = *minus* 2 meters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we specify the feet in *camera coordinates*, and if we are holding the camera level at a height of 1.7 meters, the feet of the person will be 1.7 meters *below* the pinhole position.\n",
    "\n",
    "Thinking back to the camera obscura example, the pinhole camera model specifies a 3D point $(X,Y,Z)$ in camera coordinates will be projected onto an image plane *behind* the camera:\n",
    "\n",
    "$$\n",
    "X_I = - F \\frac{X}{Z} ~~~~\n",
    "Y_I = - F \\frac{Y}{Z} ~~~~\n",
    "Z_I = -F\n",
    "$$\n",
    "\n",
    "where $F$ is the distance, in meters, from the image plane to the pinhole, i.e., the center of the lens. The following figure shows the geometry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          -1.2,
          1.2
         ],
         "y": [
          -1,
          -1
         ],
         "z": [
          -1,
          -1
         ]
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          -1.2,
          1.2
         ],
         "y": [
          1,
          1
         ],
         "z": [
          -1,
          -1
         ]
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          -1.2,
          -1.2
         ],
         "y": [
          -1,
          1
         ],
         "z": [
          -1,
          -1
         ]
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          1.2,
          1.2
         ],
         "y": [
          -1,
          1
         ],
         "z": [
          -1,
          -1
         ]
        },
        {
         "marker": {
          "color": "orange",
          "size": 3
         },
         "type": "scatter3d",
         "x": [
          -3,
          0,
          0.6
         ],
         "y": [
          1.7,
          0,
          -0.33999999999999997
         ],
         "z": [
          5,
          0,
          -1
         ]
        },
        {
         "marker": {
          "color": "orange",
          "size": 3
         },
         "type": "scatter3d",
         "x": [
          -3,
          0,
          0.6
         ],
         "y": [
          -0.3,
          0,
          0.06
         ],
         "z": [
          5,
          0,
          -1
         ]
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          0,
          1.5
         ],
         "y": [
          0,
          0
         ],
         "z": [
          0,
          0
         ]
        },
        {
         "line": {
          "color": "green"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          0,
          0
         ],
         "y": [
          0,
          1.5
         ],
         "z": [
          0,
          0
         ]
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          0,
          0
         ],
         "y": [
          0,
          0
         ],
         "z": [
          0,
          1.5
         ]
        },
        {
         "marker": {
          "color": "cyan",
          "size": 3
         },
         "mode": "markers",
         "type": "scatter3d",
         "x": [
          0
         ],
         "y": [
          0
         ],
         "z": [
          0
         ]
        }
       ],
       "layout": {
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "scene": {
         "camera": {
          "center": {
           "x": 0,
           "y": 0,
           "z": 0
          },
          "eye": {
           "x": 1.7,
           "y": -0.3,
           "z": -1.1
          },
          "up": {
           "x": 0,
           "y": -1,
           "z": 0
          }
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Pinhole Camera Model"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "F = 1 # meter\n",
    "from gtbook.diffdrive import axes, plane, ray, show_3d\n",
    "show_3d(go.Figure(data = plane(-F) + [ray(feet, -F), ray(head, -F)] + axes()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is not easy to debug algorithms with a true *upside down*  pinhole image. Instead, we can define a *virtual image plane* at a distance $F$ *in front* of the pinhole, which is non-physical, but has the advantage that the image now appears right-side up. We simply have to reflect the projected coordinates:\n",
    "\n",
    "$$\n",
    "X_V = F \\frac{X}{Z} ~~~~\n",
    "Y_V = F \\frac{Y}{Z} ~~~~\n",
    "Z_V = F\n",
    "$$\n",
    "\n",
    "The virtual image geometry is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          -1.2,
          1.2
         ],
         "y": [
          -1,
          -1
         ],
         "z": [
          1,
          1
         ]
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          -1.2,
          1.2
         ],
         "y": [
          1,
          1
         ],
         "z": [
          1,
          1
         ]
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          -1.2,
          -1.2
         ],
         "y": [
          -1,
          1
         ],
         "z": [
          1,
          1
         ]
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          1.2,
          1.2
         ],
         "y": [
          -1,
          1
         ],
         "z": [
          1,
          1
         ]
        },
        {
         "marker": {
          "color": "orange",
          "size": 3
         },
         "type": "scatter3d",
         "x": [
          -3,
          0,
          -0.6
         ],
         "y": [
          1.7,
          0,
          0.33999999999999997
         ],
         "z": [
          5,
          0,
          1
         ]
        },
        {
         "marker": {
          "color": "orange",
          "size": 3
         },
         "type": "scatter3d",
         "x": [
          -3,
          0,
          -0.6
         ],
         "y": [
          -0.3,
          0,
          -0.06
         ],
         "z": [
          5,
          0,
          1
         ]
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          0,
          1.5
         ],
         "y": [
          0,
          0
         ],
         "z": [
          0,
          0
         ]
        },
        {
         "line": {
          "color": "green"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          0,
          0
         ],
         "y": [
          0,
          1.5
         ],
         "z": [
          0,
          0
         ]
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          0,
          0
         ],
         "y": [
          0,
          0
         ],
         "z": [
          0,
          1.5
         ]
        },
        {
         "marker": {
          "color": "cyan",
          "size": 3
         },
         "mode": "markers",
         "type": "scatter3d",
         "x": [
          0
         ],
         "y": [
          0
         ],
         "z": [
          0
         ]
        }
       ],
       "layout": {
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "scene": {
         "camera": {
          "center": {
           "x": 0,
           "y": 0,
           "z": 0
          },
          "eye": {
           "x": 1.7,
           "y": -0.3,
           "z": -1.1
          },
          "up": {
           "x": 0,
           "y": -1,
           "z": 0
          }
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Pinhole Camera Model"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_3d(go.Figure(data = plane(F) + [ray(feet, F), ray(head, F)] + axes()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above still has the disadvantage that we still have to take into account the focal length $F$ when doing the projection. Dividing by the focal length yields the fundamental *pinhole projection equation*:\n",
    "\n",
    "$$\n",
    "x = \\frac{X}{Z} ~~~~ y = \\frac{Y}{Z}\n",
    "$$\n",
    "\n",
    "The dimensionless $x$ and $y$ coordinates are called the **intrinsic camera coordinates**, and can be taught of as the image of the scene in a virtual image plane situated at a focal length of 1.0. Note that the image origin at $(x,y)=(0,0)$ is the location where the *optical axis* (the blue Z-axis above) pierces the image plane. The intrinsic coordinates are in essence measuring a direction in space, but parameterized by a location in the virtual image plane rather than two angles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration\n",
    "\n",
    "> From intrinsic to sensor coordinates.\n",
    "\n",
    "Intrinsic coordinates are dimensionless, but what *pixels* in an image do they correspond to?\n",
    "Also, when we project real-valued 3D coordinates in an image, we get *real-valued* intrinsic coordinates $(x,y)$. How does that relate to integer pixel coordinates? \n",
    "To translate from intrinsic coordinates to pixel coordinates, we introduce real-valued **sensor coordinates** $(u,v)$, with the following conventions (try to draw this out for a $4\\times3$ image!):\n",
    "- the top-left of the sensor corresponds to $(u, v)=(0.0, 0.0)$;\n",
    "- the bottom-right of the sensor corresponds to $(u, v)=(W, H)$.\n",
    "\n",
    "Some things to note:\n",
    "- the vertical $v$-axis points *down*;\n",
    "- the units are in pixels (*fractional* pixels, if being precise);\n",
    "- we swapped the convention from $(r,c)\\Leftrightarrow(\\text{row},\\text{column})$ to $(u,v)\\Leftrightarrow(\\text{horizontal}, \\text{vertical})$;\n",
    "- the middle of pixel $(r, c)=(0, 0)$ has sensor coordinates $(u, v)=(0.5, 0.5)$;\n",
    "- the middle of pixel $(r, c)=(H, W)$ has sensor coordinates $(u, v)=(W-0.5, H-0.5)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest **camera calibration model** is just a linear mapping, which is most appropriate for lenses with a small field of view. For this we need four parameters $\\alpha$, $\\beta$, $u_0$, and $v_0$, to convert from intrinsic coordinates $(x,y)$ to sensor coordinates $(u,v)$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "u &= u_0 + \\alpha x \\\\\n",
    "v &= v_0 + \\beta y\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "As an example, consider the [FireFly S](https://www.flir.com/products/firefly-s/?model=FFY-U3-04S2C-C) machine vision camera, which has the following specifications:\n",
    "- sensor: [Sony IMX297](https://www.phase1vision.com/userfiles/product_files/imx273_287_296_297_flyer.pdf) (CMOS)\n",
    "- resolution: 728 x 544\n",
    "- pixel size: 6.9 $\\mu m$ (H) x 6.9 $\\mu m$ (V)\n",
    "- sensor size: 6.3mm diagonally (sanity-check this!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We typically expect the *image center*, corresponding to $(x,y)=(0.0,0.0)$, to be close to $(u_0,v_0)=(W/2,H/2)$. \n",
    "For the sensor above this would be $(u_0,v_0)=(364.0, 272.0)$. \n",
    "To compute $\\alpha$ and $\\beta$ we have to take into account the lens focal length $F$. Since $u$ and $v$ are expressed in pixels, and $x$ and $y$ are dimensionless, it is clear that $\\alpha$ and $\\beta$ must also be expressed in pixels. They can be computed as\n",
    "- $\\alpha = F k = 8mm/6.9\\mu m \\approx 1160px$\n",
    "- $\\beta = F l = 8mm/6.9\\mu m \\approx 1160px$\n",
    "\n",
    "where \n",
    "\n",
    "$$k = 1px/6.9\\mu~~~~~\\mathrm{and}~~~~l = 1px6.9\\mu$$\n",
    "\n",
    "are sensor-specific constants that indicated the number of pixels per unit of length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever $k=l$, the sensor has *square pixels*, and we can just use one proportionality constant, $f=\\alpha=\\beta$ where $f$ is then also called the *focal length*, but expressed in pixels. This is a slight abuse of terminology, as $f$ is a property of both the lense *and* the image sensor plane, but it is in widespread and we will adopt it here as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinhole Projection Equations\n",
    "\n",
    "> The final frontier.\n",
    "\n",
    "We then finally have the **fundamental pinhole projection equations**, projecting a point $P$ in 3D camera coordinates $P=(X,Y,Z)$, to its 2D image projection $p=(u,v)$ in sensor coordinates:\n",
    "\n",
    "$$\n",
    "u = u_0 + f \\frac{X}{Z} ~~~~ v = v_0 + f \\frac{Y}{Z}.\n",
    "$$\n",
    "\n",
    "To obtain integer pixel coordinates $(r,c)$, we simply need to use the *floor* function, truncating the fractional pixel sensor coordinates to a location in the image array. Note that in doing so we also flip horizontal and vertical:\n",
    "\n",
    "$$\n",
    "(r,c) = (\\lfloor v \\rfloor, \\lfloor u \\rfloor)\n",
    "$$\n",
    "\n",
    "We can also go the other way, *calibrating* the sensor coordinates $(u,v)$ to the dimensionless intrinsic coordinates $(x,y)$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x &= (u-u_0)/f \\\\\n",
    "u &= (v-v_0)/f\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration in GTSAM\n",
    "\n",
    "> Everything above and more.\n",
    "\n",
    "In GTSAM you have access to several calibration models, with the simple one above corresponding to `gtsam.Cal3_S2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_8mm_FireFlyS = gtsam.Cal3_S2(fx=1160, fy=1160, s=0, u0=364, v0=272)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments `fx` and `fy` above correspond to $\\alpha$ and $\\beta$, and for now you can ignore the extra `s` argument, denoting *skew* which almost always zero for modern sensors.\n",
    "We can then convert from integer pixel coordinates to intrinsic coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image[0,0] -> (u,v)=(0.5px,0.5px) -> (x,y)=(-0.313,-0.234) \n",
      "image[272,364] -> (u,v)=(364.5px,272.5px) -> (x,y)=(0.0,0.0) \n",
      "image[543,727] -> (u,v)=(727.5px,543.5px) -> (x,y)=(0.313,0.234) \n"
     ]
    }
   ],
   "source": [
    "def calibration_demo(cal:gtsam.Cal3_S2, row:int, col:int):\n",
    "    \"\"\"Convert from integer pixel coordinates to sensor and then intrinsic coordinates.\"\"\"\n",
    "    assert isinstance(row,int) and isinstance(col,int)\n",
    "    u, v = 0.5+col, 0.5+row\n",
    "    x, y = cal.calibrate([u,v])\n",
    "    print(f\"image[{row},{col}] -> (u,v)=({round(u,2)}px,{round(v,2)}px) -> (x,y)=({round(x,3)},{round(y,3)}) \")\n",
    "\n",
    "calibration_demo(cal_8mm_FireFlyS, row=0, col=0)\n",
    "calibration_demo(cal_8mm_FireFlyS, row=272, col=364)\n",
    "calibration_demo(cal_8mm_FireFlyS, row=543, col=727)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although the intrinsic coordinates are the dimensionless, you can interpret them as fractions of the focal length. \n",
    "Also, the above was a \"calibration\" example where we go from pixel coordinates to intrinsic coordinates. The calibration objects in GTSAM also provide an `uncalibrate` method which goes the other way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x,y)=(0,0) -> (u,v)=(364.0px,272.0px)\n"
     ]
    }
   ],
   "source": [
    "u,v = cal_8mm_FireFlyS.uncalibrate([0,0])\n",
    "print(f\"(x,y)=(0,0) -> (u,v)=({round(u,2)}px,{round(v,2)}px)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Field of View\n",
    "\n",
    "The last concept we need the **field of view** or **FOV** of a camera.\n",
    "Because the *left-most* ray we can see has $u=0$, it corresponds to $x=-u_0/f\\approx-W/2f$.\n",
    "The horizontal FOV can then be calculated by\n",
    "\n",
    "$$\\mathrm{HFOV} = 2 \\arctan(W/2f)~~\\mathrm{rad} = 360 \\arctan(W/2f) / \\pi~~\\mathrm{degrees}$$\n",
    "\n",
    "For the sensor-lens combination above we get a relatively narrow field of view of about 35 degrees:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HFOV for f=1160 is 34.84 degrees\n"
     ]
    }
   ],
   "source": [
    "f = 1160\n",
    "hfov = 360 * math.atan(728/(2*f)) / math.pi\n",
    "print(f\"HFOV for f={f} is {hfov:.2f} degrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Field of view *increases* with decreasing focal length, e.g., a lens of 4mm will give us a bit less than double that HFOV, of around 64 degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HFOV for f=579.7 is 64.25 degrees\n"
     ]
    }
   ],
   "source": [
    "f_wide = 4e-3/6.9e-6\n",
    "hfov_wide = 360 * math.atan(728/(2*f_wide)) / math.pi\n",
    "print(f\"HFOV for f={f_wide:.1f} is {hfov_wide:.2f} degrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also ask the opposite question: what lens focal length should I choose to get a certain filed of view. For example, for a *diagonal* field of view we have\n",
    "\n",
    "$$\\mathrm{DFOV} = 360 \\arctan(\\sqrt{W^2+H^2}/2f) / \\pi~~\\mathrm{degrees}$$\n",
    "\n",
    "and hence\n",
    "\n",
    "$$f = \\frac{\\sqrt{W^2+H^2}}{2 \\tan(\\mathrm{DFOV} \\pi/360)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f45 = 454.0 pixels, F45 = 3.1 mm\n"
     ]
    }
   ],
   "source": [
    "f45 = math.sqrt(728**2+544**2)/2/math.tan(math.pi/4)\n",
    "F45 = f45*6.9e-3\n",
    "print(f\"f45 = {np.round(f45)} pixels, F45 = {np.round(F45,1)} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stereo Vision\n",
    "\n",
    "> Given two cameras, we can calculate depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using two cameras, we can triangulate features seen in both cameras to calculate its location in space. \n",
    "Given a projection $p=(u,v)$ of a point $P=(X,Y,Z)$ in a single camera we can only determine the *ray* on which the point $P$ must lie.\n",
    "However, if we see *two* projections of the same feature in two cameras, placed side by side, we can *triangulate* the location of $P$.\n",
    "In particular, let us name the cameras \"Left\" and \"Right\", abbreviated as \"L\" and \"R\", and let the two projections be $p_L=(u_L,v_L)$ and $p_R=(u_R,v_R)$. How could we recover the coordinates $(X,Y,Z)$ in, say, the *left* camera coordinate frame?\n",
    "\n",
    "We can easily work out the answer *if* the cameras have the same calibration *and* the camera pair is in a \"stereo\" configuration. The latter means that the cameras have exactly the same orientation with respect to the world, and the right camera is displaced only horizontally with respect to the left camera. We call the displacement the **stereo baseline** $B$. In that case we have\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "u_L &= u_0 + f \\frac{X}{Z}~~~~v_L = v_0 + f \\frac{Y}{Z} \\\\\n",
    "u_R &= u_0 + f \\frac{X-B}{Z}~~~~v_R = v_0 + f \\frac{Y}{Z}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two interesting things to note: (a) $u_L$ and $u_R$ differ only because the $X$ coordinate of the point $P$, measured in the right camera, is $B$ less than its value in the left camera.\n",
    "and (b) $v_L$ and $v_R$ have the same value: *corresponding* points in a stereo pair lie on the same scanline in the images. We can use the first fact to calculate the *unknown depth* $Z$, by defining the **disparity** $d$ as the difference of $u_L$ and $u_R$,\n",
    "\n",
    "$$\n",
    "d \\doteq u_L - u_R = f \\frac{X}{Z} - f \\frac{X-B}{Z},\n",
    "$$\n",
    "\n",
    "and then performing some algebraic manipulation to obtain the **fundamental stereo equation**:\n",
    "\n",
    "$$\n",
    "Z = B \\frac{f}{d}.\n",
    "$$\n",
    "\n",
    "The fraction $f/d$ is dimensionless, as both disparity $d$ and focal length $f$ are expressed in pixels, and hence the resulting depth $Z$ is expressed in the units of the baseline $B$. Using the other equation we can now completely reconstruct the location of the point $P$ in (left) camera coordinates:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}X\\\\Y\\\\Z\\end{bmatrix}\n",
    "= \\begin{bmatrix}Z(u_L-u_0)/f\\\\Z(v_L-v_0)/f\\\\B f/d\\end{bmatrix}\n",
    "= B \\frac{f}{d} \\begin{bmatrix}(u_L-u_0)/f\\\\(v_L-v_0)/f\\\\1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Stereo cameras are used very often on robotics platforms because of this ability to reconstruct the world in 3D, at least in in principle. This is akin to our own (human) ability to perceive depth by virtue of having two eyes, a feature we have in common with many animals - primarily predators, who need accurate depth vision to hunt prey. In practice, using a stereo camera is not as straightforward, as it has to be carefully calibrated and finding *correspondences* between left and right cameras is not always straightforward. However, the latter has been alleviated quite a bit by recent advances in neural networks, which we will discuss in the next section."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "S53_duckiebot_sensing.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_metadata": {
   "affiliation": "Georgia Institute of Technology",
   "author": "Frank Dellaert and Seth Hutchinson",
   "title": "Introduction to Robotics"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
