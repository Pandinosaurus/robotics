{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gtbook/robotics/blob/main/S55_duckiebot_decision_theory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JoW4C_OkOMhe",
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U gtbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "10-snNDwOSuC",
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import gtsam \n",
    "\n",
    "from gtbook.discrete import Variables\n",
    "from gtbook.display import show, pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAvx4-UCNzt2"
   },
   "source": [
    "# Path Planning\n",
    "\n",
    "> Samples are useful for planning as well.\n",
    "\n",
    "**This Section is still in draft mode and was released for adventurous spirits (and TAs) only.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div align='center'>\n",
       "        <img src='https://github.com/gtbook/robotics/blob/main/Art/steampunk/S55-Two-wheeled%20Toy%20Robot-07.jpg?raw=1' style='height:256 width:100%'/>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gtbook.display import randomImages\n",
    "from IPython.display import display\n",
    "display(randomImages(5, 5, \"steampunk\", 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path planning is the problem of finding a collision-free path for\n",
    "the robot from its starting configuration to a goal configuration.\n",
    "This is one of the oldest fundamental problems in robotics.\n",
    "Ideally, a path planning algorithm would guarantee to find a collision-free path whenever such a path\n",
    "exists. Such algorithms are said to be **complete**.\n",
    "Unfortunately, it has been shown that the path planning problem is NP complete.\n",
    "Numerous hardness results have been obtained for different versions of the problem,\n",
    "but the sad fact is that planning collision-free paths is generally intractable\n",
    "for even moderately complex robotic systems.\n",
    "For this reason, modern path planning algorithms try to strike a balance between\n",
    "completeness (often settling for weaker variations on this idea)\n",
    "and efficiency,\n",
    "while finding solution paths for most typical problems.\n",
    "\n",
    "In this section, we will describe several approaches to path planning,\n",
    "all of which operate in the configuration space, to illustrate\n",
    "the range of trade-offs that exist in this domain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Space Obstacles\n",
    "\n",
    "Although the robot moves physically in its workspace, the path planning problem is more easily addressed\n",
    "if we work directly in the robot's configuration space.\n",
    "As in Section 5.2, we will denote a robot configuration by $q$ and the configuration space of the robot by ${\\cal Q}$.\n",
    "In order to plan collision-free paths, it is useful to partition the configuration space into \n",
    "the set of collision-free configurations, ${\\cal Q}_\\mathrm{free}$ (often called the *free configuration space*)\n",
    "and the set of configurations that result in a collision, ${\\cal Q}_\\mathrm{obst}$,\n",
    "which is sometimes referred to as the *configuration space obstacle region*.\n",
    "\n",
    "Let $R(q)$ denote the set of points in the workspace that are occupied by the robot when the robot is in configuration $q$,\n",
    "and let ${\\cal O}$ denote the obstacle region in the workspace.\n",
    "We can define the set ${\\cal Q}_\\mathrm{obst}$ as\n",
    "\n",
    "$$\n",
    "{\\cal Q}_\\mathrm{obst} = \\{ {\\cal Q} \\mid R(q) \\cap {\\cal O} = \\emptyset \\}\n",
    "$$\n",
    "\n",
    "The free configuration space is merely the complement of this set in $\\cal Q$:\n",
    "\n",
    "$$\n",
    "{\\cal Q}_\\mathrm{free} = {\\cal Q} \\setminus {\\cal Q}_\\mathrm{obst}\n",
    "$$\n",
    "\n",
    "We can now formally define a free path as a continuous map from the unit interval\n",
    "(or any convenient interval that represents path length) as $\\gamma : [0,1] \\rightarrow {\\cal Q}_\\mathrm{free}$,\n",
    "such that $q(0) = q_\\mathrm{init}$ and $q(1) = q_\\mathrm{goal}$.\n",
    "In some cases we require that $\\gamma$ also be differntiable, but this will not be necessary for our DDR.\n",
    "\n",
    "When the dimension of the configuration space is small (e.g., ${\\cal Q} \\subset \\mathbb{R}^2$),\n",
    "it may be possible to explicitly compute ${\\cal Q}_\\mathrm{free}$;\n",
    "however, the time required for this computation grows exponentially with the\n",
    "dimension of the configuration space, so this approach is not taken for even moderately complex robotic systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration\n",
    "\n",
    "In Chapter 4 we saw how the value function could be used to plan a path that led a robot with stochastic actions to a goal while avoiding obstacles.\n",
    "We can apply this same method to the problem of planning collision-free paths in the configuration space.\n",
    "We merely place a large negative reward along the configuration space obstacle boundaries, and a large positive reward at the goal configuration.\n",
    "We can then use value iteration to compute an approximation to the value function over ${\\cal Q}_\\mathrm{free}$,\n",
    "and merely follow the gradient\n",
    "of the value function from the robot's initial configuration until it reaches the goal.\n",
    "In cases where the robot's actions are not stochastic, we merely replace the probabilistic action model by a conditional probability\n",
    "function that assigns probability one to the action's defined outcome\n",
    "(i.e., there is no uncertainty in the result of applying the action).\n",
    "\n",
    "There are several disadvantages to this approach.\n",
    "First, to apply value iteration, we must first discretize the configuration space (e.g., using a 2D grid).\n",
    "Thus, we are computing the value function over an approximate representation, the fidelity of which\n",
    "depends on the resolution of the grid.\n",
    "It is possible, if the resolution is not good enough, that this method could fail to find a path to\n",
    "the goal, even if a path for the robot exists.\n",
    "Second, even though our planning problem is to find a path from $q_\\mathrm{init}$ to $q_\\mathrm{goal}$,\n",
    "the value function encodes the cost to reach the goal from *every* cell in the grid, including parts\n",
    "of the grid that may never be visited by the robot.\n",
    "Therefore, using the value function to solve a single path planning problem can be very inefficient,\n",
    "since it essentially computes a path to the goal from *every* configuration in the grid.\n",
    "Finally, the cost of computing the value function grows exponentially with the dimension of the configuration space,\n",
    "precluding the use of this method to plan paths for more complex robots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Potential Fields\n",
    "\n",
    "Instead of exhastively applying value iteration to a 2D grid representation of the configuration space,\n",
    "we could try to construct a function that can be expressed in closed-form, such that following\n",
    "the gradient of this function would lead to the goal configuration while avoiding any configuration\n",
    "space obstacles.\n",
    "Artificial potential functions aim to do just this.\n",
    "\n",
    "The basic idea is simple: define a potential function on ${\\cal Q}_\\mathrm{free}$ with a single\n",
    "global minimum at $q_\\mathrm{goal}$, and with arbitrarily high potential values on\n",
    "the boundary of ${\\cal Q}_\\mathrm{obst}$. \n",
    "Because such a function would be convex,\n",
    "and because the potential increases arbitrarily at obstacle boundaries,\n",
    "gradient descent will achieve the goal of constructing a collision-free path to the goal.\n",
    "Unfortunately, we can almost never construct such a function.\n",
    "Convexity is the problem; at the moment we introduce obstacles, it becomes very difficult to\n",
    "construct a convex potential function with the desired behavior.\n",
    "\n",
    "It is fairly easy, however, to construct a function with a minimum at $q_\\mathrm{goal}$ \n",
    "(though it will likely be one of many minima for the function)\n",
    "that ensures collision-free paths.\n",
    "We can define such a potential function as\n",
    "\n",
    "$$\n",
    "U(q) = U_\\mathrm{attr}(q) + U_\\mathrm{rep}(q)\n",
    "$$\n",
    "\n",
    "in wihch $U_\\mathrm{attr}$ is the *attractive potential$ with a single global minimum at $q_\\mathrm{goal}$,\n",
    "and $U_\\mathrm{rep}$ is the repulsive potential, whose value goes to infinity on the boundary\n",
    "of ${\\cal Q}_\\mathrm{obst}$. \n",
    "\n",
    "There are many possible candidates for these two potentials, but it the basic behavior\n",
    "can be captured by using a parabolic well for $U_\\mathrm{attr}$, and defining $U_\\mathrm{rep}$\n",
    "in terms of the inverse distance to the nearest obstacle:\n",
    "\n",
    "$$ \n",
    "U_\\mathrm{attr}(q) = \\frac{1}{2} \\| q -  q_\\mathrm{goal} \\|^2 ~~~~~~~~~~~~ U_\\mathrm{rep}(q) = \\frac{1}{d(q)}\n",
    "$$\n",
    "\n",
    "in which $d(q)$ is defined as the minimum distance from configuration $q$ to the boundary of\n",
    "${\\cal Q}_\\mathrm{obst}$\n",
    "\n",
    "$$ d(q) = \\min_{q' \\in \\partial {\\cal Q}_\\mathrm{obst} } \\| q - q'\\|^{\\frac{1}{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path planning can now be implemented using simple gradient descent.\n",
    "Let $q^0 = q_\\mathrm{init}$, and iterate over $k$ until $\\| q^k - q_\\mathrm{goal} \\| < \\epsilon$\n",
    "\n",
    "$$\n",
    "q^{k+1} = q^k - \\alpha \\nabla U(q)\n",
    "$$\n",
    "\n",
    "Note that this algorithm stops making progress if $\\nabla U(q)=$,\n",
    "which occurs for any local minimum in the potential field.\n",
    "This is the primary drawback for potential field planners.\n",
    "Nevertheless, the method is fast, and can be very effective for path planning problems that\n",
    "aren't too difficult (e.g., when the path to the goal does not pass through the basin of attraction\n",
    "for any local minimum in the field)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the basic idea behind potential field planning is similar to the basic idea behind\n",
    "using the value function to construct a path:\n",
    "Create a function whose optimal value is at the goal\n",
    "(this is a maximum of the value function, but a minimum of the potential fiels),\n",
    "and assign high cost (or, in the case of the value function, negative reward)\n",
    "along the boundary of ${\\cal Q}_\\mathrm{obst}$.\n",
    "Then use gradient descent to find the path to the goal.\n",
    "A key difference between the two methods is that, while value iteration requires global\n",
    "computation of the value function, potential field planning evaluates $U$ (and $\\nabla U$) *only*\n",
    "at those $q^k$ that lie on the constructed path to the goal.\n",
    "This provides a significant increase in computational efficiency, and in many cases\n",
    "it is possible to use potential fields methods for real-time applications.\n",
    "The second key difference is that value functions always have a single optimum, and that gradient\n",
    "descent is guaranteed to find it, unlike potential fields that are apt to be trapped\n",
    "in local minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Roadmaps (PRMs)\n",
    "\n",
    "As discussed above, the value function is guaranteed to find a path because it essentially explores the entire configuration space (applying dynamic programming outward from the goal configuration), while potential field planning is efficient because it focuses computation on the search for an individual path.\n",
    "A compromise approach would be to build a global representation, but to encode only a small number of\n",
    "paths in that representation.\n",
    "Probabilistic Roadmaps (PRMs) do just this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PRM is a graph $G=(V,E)$ that is embedded in the configuration space.\n",
    "Vertices correspond to configurations, and edges correspond to free paths.\n",
    "A PRM is constructed by randomly sampling the configuration space to generate\n",
    "the set of vertices, rejecting any samples that lie in ${\\cal Q}_\\mathrm{obst}$.\n",
    "Once the vertices have been generated, a simple local path planner is used\n",
    "to connect vertices $v,v'$ when the corresponding configurations $q,q'$ are sufficiently\n",
    "close (e.g., $\\|q - q'\\| < d_\\mathrm{max}$).\n",
    "It is common to use a simple straight-line planner for these connections: an\n",
    "edge connecting $v$ and $v'$ is added to $E$ when the straight-line path from $q$ to $q'$ is collision-free.\n",
    "There are, of course, many variations, nuances, and implementation details that we cannot cover here,\n",
    "but this is the basic algorithm: randomly generate configurations and connect neighboring configurations when\n",
    "possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a PRM has been constructed, path planning proceeds in two steps.\n",
    "First, generate vertices $v_\\mathrm{init}$ and $v_\\mathrm{goal}$\n",
    "corresponding to configurations $q_\\mathrm{init}$ and $q_\\mathrm{goal}$, and connect these\n",
    "to the existing graph.\n",
    "Second, search the graph for a path from $v_\\mathrm{init}$ to $v_\\mathrm{goal}$ in $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be clear that such a method has no hope to yield a complete algorithm.\n",
    "The mere fact that every node in the graph is the result of random sampling is enough\n",
    "to preclude any proof that this approach will guarantee to find a path when a path exists.\n",
    "There is, however, another useful completeness concept that applies in this case.\n",
    "Suppose a free path exists.\n",
    "Let $p_f(n)$ denote the probability that the algorithm fails to find a path\n",
    "after adding $n$ random vertices to the graph.\n",
    "An path planning algorithm is said to be **probabilistically complete** if\n",
    "\n",
    "$$ \\lim_{n\\rightarrow \\infty} p_f(n) = 0\n",
    "$$\n",
    "\n",
    "Not only are PRM methods probabilistically complete, but in addition\n",
    "they have the property that $p_f(n)$ decreases to zero exponentially as $n$ increases.\n",
    "This is a powerful result, even if it fails to provide a deterministic guarantee of completeness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RRT\n",
    "\n",
    "> Grow a tree to the goal.\n",
    "\n",
    "An alternative to building a single, global PRM is to grow a random tree from the initial\n",
    "configuration $q_\\mathrm{init}$ until one of the leaf nodes in the tree can be connected\n",
    "to $q_\\mathrm{goal}$.\n",
    "This is the approach taken with Rapidly-Exploring Random Trees (RRTs).\n",
    "\n",
    "An RRT is constructed by iteratively adding randomly generated nodes to an existing\n",
    "tree.\n",
    "Let $T_k$ denote the tree that exists at the $k^{th}$ iteration.\n",
    "A new node is added to the tree as follows:\n",
    "\n",
    "1. Randomly choose a configuration $q_\\mathrm{rand}$.\n",
    "2. Let $q_\\mathrm{near}$ be the node in the current tree $T_k$ that is nearest to $q_\\mathrm{rand}$.\n",
    "3. Create a new node $q_\\mathrm{new}$ by taking a small step from $q_\\mathrm{near}$ in\n",
    "the direction of $q_\\mathrm{rand}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with PRMs, there are many variations, nuances, and implementation details,\n",
    "but the above three steps capture the essential idea of RRTs.\n",
    "For our DDR, *taking a small step* can be implemented by using a simple two-step straight-line planner.\n",
    "First, rotate the DDR so that its steering direction \"points toward\" $q_\\mathrm{rand}$.\n",
    "Second, move in the forward direction by some fixed amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RRTs enjoy the same probabilistic completeness properties as PRM-based planners.\n",
    "In addition, it has been shown that the distribution of nodes in the tree converges\n",
    "to the sampling distribution (e.g., if $q_\\mathrm{rand}$ is generated by sampling from a uniform\n",
    "distribution on the configuration space, then the distribution of nodes\n",
    "in $T_k$ will converge to a uniform distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RRTs have become increasingly popular in the robot motion planning community, for reasons that will become more apparent when we revisit RRT-style planning for aerial drones in Chapter 7.\n",
    "For now, we will use a very simple implementation of RRTs to construct motion plans for our DDR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 0.785398)\n",
      " (10, 5, 1.5708)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = gtsam.Pose2(1,2,np.radians(45))\n",
    "goal = gtsam.Pose2(10,5, np.radians(90))\n",
    "print(start, goal)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "S55_duckiebot_decision_theory.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_metadata": {
   "affiliation": "Georgia Institute of Technology",
   "author": "Frank Dellaert and Seth Hutchinson",
   "title": "Introduction to Robotics"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
