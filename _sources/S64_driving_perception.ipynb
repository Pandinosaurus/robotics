{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gtbook/robotics/blob/main/S64_driving_perception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JoW4C_OkOMhe",
    "outputId": "867d9053-0888-4148-8c0e-2286bfc18487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -q -U gtbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "10-snNDwOSuC"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "try:\n",
    "    import google.colab\n",
    "except:\n",
    "    import plotly.io as pio\n",
    "    pio.renderers.default = \"png\"\n",
    "\n",
    "import gtsam \n",
    "from gtbook import driving\n",
    "from gtbook.display import show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAvx4-UCNzt2"
   },
   "source": [
    "# PoseSLAM\n",
    "> PoseSLAM is SLAM with pose priors and relative pose constraints only.\n",
    "\n",
    "**This Section is still in draft mode and was released for adventurous spirits (and TAs) only.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div align='center'>\n",
       "        <img src='https://github.com/gtbook/robotics/blob/main/Art/steampunk/S64-Autonomous%20Vehicle%20with%20LIDAR%20and%20cameras-02.jpg?raw=1' style='height:256 width:100%'/>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gtbook.display import randomImages\n",
    "from IPython.display import display\n",
    "display(randomImages(6, 4, \"steampunk\", 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Closest Points\n",
    "\n",
    "> ICP is a seminal method to align 2 point clouds.\n",
    "\n",
    "**Iterative closest points** or **ICP** is a method to align two point clouds, e.g., two successive LIDAR scans. Let us use superscripts $a$ and $b$ to distinguish the two point clouds, and the points therein. Under the assumption that we have a good initial estimate $\\hat{T^a_b}$ for the relative pose $T^a_b$ between the two point clouds, we iterate between two steps:\n",
    "\n",
    "- find closest point correspondences between the two clouds;\n",
    "- re-estimate the relative pose $\\hat{T^a_b}$ between the two clouds.\n",
    "\n",
    "These two steps are iterated until convergence, hence the name. Below we  explain both steps in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Closest Points\n",
    "\n",
    "The first step is the easiest: for each point $P^a_j$ in the first point cloud, find the closest point $P^b_j$ in the second point cloud. Stated formally we have:\n",
    "\n",
    "$$\n",
    "P^b_j = \\arg \\min_{P^b} \\| P^b - P^a_j\\|^2\n",
    "$$\n",
    "\n",
    "where minimizing the square is just as good as minimizing the distance, because they are monotonically related. This is known as the **nearest neighbor** problem, and doing so for all points is the **all nearest neighbors** problem.\n",
    "\n",
    "The brute force algorithm of iterating over all points in the second cloud can be quite slow, and indeed finding all nearest neighbors that way has quadratic complexity. However, very fast *approximate* nearest neighbor algorithms are available. Many of these use specialized data structures, such as \"KD-trees\" or \"Oct-trees\" (in 3D). While the details are out of scope, intuitively these data structures  recursively divide up the point clouds into sub-clouds, such that sub-clouds unlikely to contain the nearest neighbor can be quickly excluded. We build his data structure ones for the beat second cloud, and then use it for all nearest neighbor searches, leading to complexity which is approximately $O(N \\log N$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Pairwise Transform\n",
    "\n",
    "The second step is the more interesting one: given a set of closest point pairs $(P^a_j, P^b_j)$, how can we estimate from those the relative pose $\\widehat{T^a_b}$ between two points clouds? This is known as the **pose alignment** problem.\n",
    "\n",
    "Let us first assume that the two point clouds only differ by a rotation $R^a_b$. When this is the case, and assuming we have corresponding points $P^a$ and $P^b$, then each point $P^a$ in the first cloud can be expressed as a function of a point $P^b$ in the second cloud:\n",
    "\n",
    "$$\n",
    "P^a = R^a_b P^b\n",
    "$$\n",
    "\n",
    "One might be tempted to think that therefore \n",
    "\n",
    "$$\n",
    "R^a_b = P^a (P^b)^T\n",
    "$$\n",
    "\n",
    "but that is just silly (think about why!). Interestingly, though, if we form the matrix\n",
    "\n",
    "$$\n",
    "H = \\sum_j P^a_j (P^b_j)^T\n",
    "$$\n",
    "\n",
    "by summing over at least 3 point pairs $(P^a_j, P^b_j)$, it turns out that the rotation matrix $\\widehat{R^a_b}$ closest to $H$ in the least squares sense *is* the best possible estimate for the unknown rotation $R^a_b$. In addition, using the *singular value decomposition* $H=U\\Lambda V^T$ from linear algebra, it is *very* easy to compute:\n",
    "\n",
    "$$\n",
    "\\widehat{R^a_b} = U V^T\n",
    "$$\n",
    "\n",
    "Interesting aside: this problem is known as the *orthogonal Procrustes problem* and its solution via SVD been known since 1966, from a paper by Peter Schönemann in a *psychology* journal.\n",
    "\n",
    "The above solves the problem when there is only rotation, but it turns out that the best possible translation estimate will always align both *centroids* of the point clouds. Hence, when there is translation present, we simply compute the matrix $H$ from the *centered* points, \n",
    "\n",
    "$$\n",
    "H = \\sum_j (P^a_j-C^a) (P^b_j-C^b)^T\n",
    "$$\n",
    "\n",
    "where the point cloud centroids $C^a$ and $C^b$ are computed as \n",
    "$$\n",
    "C^a = \\frac{1}{N} \\sum_j P^a_j\\text{  and  }C^b = \\frac{1}{N} \\sum_j P^b_j.\n",
    "$$\n",
    "\n",
    "Given the estimated rotation $\\widehat{R^a_b}$, the translation estimate $\\widehat{t^a_b}$ can be estimated from \n",
    "\n",
    "$$\n",
    "C^a = \\widehat{R^a_b} C^b + \\widehat{t^a_b},\n",
    "$$\n",
    "\n",
    "and the final relative pose estimate is given by $\\widehat{T^a_b} =(\\widehat{R^a_b}, \\widehat{t^a_b})$. By the way, all of the above math is identical for both the 2D and 3D case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLAM\n",
    "\n",
    "> SLAM is Simultaneous Localization and Mapping.\n",
    "\n",
    "**SLAM** is **Simultaneous Localization and Mapping**. In the SLAM\n",
    "problem the goal is to localize a robot using the information coming\n",
    "from the robot’s sensors. The additional wrinkle in SLAM is that we do\n",
    "*not* know the map a priori, and hence we have to infer the unknown map\n",
    "simultaneously with localization with respect to the evolving map.\n",
    "\n",
    "**PoseSLAM** is a variant of SLAM that uses pose constraints as the\n",
    "basic building block, and where we optimize over the unknown vehicles\n",
    "poses. We do not explicitly optimize over a map: that is reconstructed\n",
    "after the fact.\n",
    "\n",
    "To represent the pose of a vehicle, recall that 2D poses\n",
    "$T\\doteq(x,y,\\theta)$ form the Special Euclidean group $SE(2)$, and\n",
    "can be represented by $3\\times3$ matrix of the form\n",
    "$$\n",
    "T=\\left[\\begin{array}{cc|c}\n",
    "\\cos\\theta & -\\sin\\theta & x\\\\\n",
    "sin\\theta & \\cos\\theta & y\\\\\n",
    "\\hline 0 & 0 & 1\n",
    "\\end{array}\\right]=\\left[\\begin{array}{cc}\n",
    "R & t\\\\\n",
    "0 & 1\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "with the $2\\times1$ vector $t$\n",
    "representing the position of the vehicle, and $R$ the $2\\times2$\n",
    "rotation matrix representing the vehicle’s orientation in the plane.\n",
    "\n",
    "Note that this representation generalizes equally to three dimensions,\n",
    "but of course $t$ will be a three-vector, and $R$ will be a $3\\times3$\n",
    "rotation matrix representing the 3DOF attitude of the vehicle. The\n",
    "latter can be decomposed into roll, pitch, and yaw, if so desired.\n",
    "\n",
    "The PoseSLAM problem is then:\n",
    "\n",
    "> given a set of noisy relative measurements or **pose constraints**\n",
    "> $\\tilde{T}_{ij}$, recover the optimal set of poses $T_{i}^{*}$ that\n",
    "> maximizes the posteriori probability, i.e., recover the MAP solution.\n",
    "\n",
    "In the case of mapping for autonomous driving, these relative\n",
    "measurements can be derived from performing ICP between overlapping\n",
    "scans. We can use GPS and/or IMU measurements to decide which scans\n",
    "overlap, so that we do not have to compare $O(n^{2})$ scans. Depending\n",
    "on the situation, we can optimize for 3D or 2D poses, in the way we will\n",
    "discus below. Afterwards, we can reconstruct a detailed map by\n",
    "transforming the local LIDAR scans into the world frame, using the\n",
    "optimized poses $T_{i}^{*}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The PoseSLAM Factor Graph\n",
    "\n",
    "In our factor-graph-based view of the world, a pose constraint is\n",
    "represented as a factor. As before, the factor graph represent the\n",
    "posterior distribution over the unknown pose variables\n",
    "$\\mathcal{T}=\\{X_{1}\\dots X_{5}\\}$ given the known measurements:\n",
    "\n",
    "$$\n",
    "\\phi(\\mathcal{T})=\\prod_{i}\\phi_{i}(\\mathcal{T}_{i}).\n",
    "$$\n",
    "\n",
    "The factor graph encodes which factors are connected to which variables,\n",
    "exposing the sparsity pattern of the corresponding estimation problem.\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://github.com/gtbook/robotics/blob/main/Figures6/PoseSLAM-FG.png?raw=1\" id=\"fig:PoseSLAMFG\" style=\"width:60.0%\" /><figcaption><span id=\"fig:PoseSLAMFG\" label=\"fig:PoseSLAMFG\">[fig:PoseSLAMFG]</span> PoseSLAM factor graph example.</figcaption>\n",
    "</figure>\n",
    "\n",
    "An example is shown in Figure\n",
    "<a href=\"#fig:PoseSLAMFG\" data-reference-type=\"ref\" data-reference=\"fig:PoseSLAMFG\">1</a>.\n",
    "The example represents a vehicle driving around, and taking LIDAR scans\n",
    "at 5 different world poses, represented by $T_{1}$ to $T_{5}$.\n",
    "The factors $f_{1}$ to $f_{4}$ are binary factors representing the pose\n",
    "constraints obtained by matching successive LIDAR scans. The factor\n",
    "$f_{5}(T_{5},T_{2})$ is a so-called “loop closure” constraint:\n",
    "rather than derived from two successive scans, this one is derived from\n",
    "matching the scan taken at $T_{5}$ with the one at $T_{2}$.\n",
    "Detecting such loops can be done through a variety of means. The final,\n",
    "unary factor $f_{0}(T_{1})$ is there to “anchor” the solution to the\n",
    "origin: if it is not there, the solution will be undetermined. Another\n",
    "way to anchor the solution is to add unary factors at every time-step,\n",
    "derived from GPS.\n",
    "Finding the MAP in the case that variables are continuous and\n",
    "measurements are linear combinations of them can be done via\n",
    "least-squares. Above we have discussed MAP inference for discrete\n",
    "variables, and we have discussed probability distributions for\n",
    "continuous variables, but we have never put the two together. In the\n",
    "case of measurements corrupted by zero-mean Gaussian noise, we can\n",
    "recover the MAP solution by minimization. Recall that a multivariate\n",
    "Gaussian density **with mean** $\\mu$ and **variance** $\\sigma^{2}$ is\n",
    "given by\n",
    "\n",
    "$$\n",
    "\\mathcal{N} x\\mu\\sigma^2=\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\exp\\left\\{ -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{2}\\right\\} .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we focus our attention in PoseSLAM on just the x coordinates, then we\n",
    "predict relative measurements $\\tilde{x}_{ij}$ by\n",
    "\n",
    "$$\n",
    "\\tilde{x}_{ij}\\approx h(x_{i,}x_{j})=x_{j}-x_{i}\n",
    "$$\n",
    " and each factor in\n",
    "Figure\n",
    "<a href=\"#fig:PoseSLAMFG\" data-reference-type=\"ref\" data-reference=\"fig:PoseSLAMFG\">1</a>\n",
    "could be written as\n",
    "\n",
    "$$\n",
    "\\phi(x_{i},x_{j})=\\frac{1}{\\sqrt{2\\pi}}\\exp\\left\\{ -\\frac{1}{2}\\left(x_{j}-x_{i}-\\tilde{x}_{ij}\\right)^{2}\\right\\} ,\n",
    "$$\n",
    "\n",
    "where we assumed $\\sigma=1$ for now. By taking the negative log,\n",
    "maximizing the posterior corresponds to minimizing the following sum of\n",
    "squares, where sum ranges over all $(i,j)$ pairs for which we have a\n",
    "pairwise measurement:\n",
    "\n",
    "$$\n",
    "\\mathcal{X}^{*}=\\arg\\min_{\\mathcal{X}}\\sum_{k}\\frac{1}{2}\\left(h(x_{i},x_{j})-\\tilde{x}_{ij}\\right)^{2}=\\arg\\min_{\\mathcal{X}}\\sum_{k}\\frac{1}{2}\\left(x_{j}-x_{i}-\\tilde{x}_{ij}\\right)^{2}.\n",
    "$$\n",
    "\n",
    "Linear least squares problems like these are easily solved by numerical\n",
    "computing packages like MATLAB or numpy.\n",
    "\n",
    "Unfortunately, in the PoseSLAM case we cannot use linear least squares,\n",
    "because poses are not simply vectors, and the measurements are not\n",
    "simply linear functions of the poses. Indeed, in PoseSLAM both the\n",
    "prediction $h(T_{i},T_{j})$ and the measurement $\\tilde{T}_{ij}$\n",
    "are relative poses. The measurement prediction function $h(.)$ is given\n",
    "by \n",
    "$$\n",
    "h(T_{i},T_{j})=T_{i}^{-1}T_{j}\n",
    "$$\n",
    " and the\n",
    "measurement error to be minimized is\n",
    "\n",
    "$$\n",
    "\\frac{1}{2}\\left\\Vert \\log\\left(\\tilde{T}_{ij}^{-1}T_{i}^{-1}T_{j}\\right)\\right\\Vert ^{2}\n",
    "$$\n",
    "\n",
    "where $\\log:SE(2)\\rightarrow\\mathbb{R}^3$ denotes a map from $SE(2)$ to a\n",
    "three-dimensional local coordinate vector $\\xi$, which will be defined\n",
    "in detail below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Optimization for PoseSLAM\n",
    "\n",
    "There are two ways out of the nonlinear quandary. The first is to\n",
    "realize that the only non-linearities stem from the $\\sin$ and $\\cos$\n",
    "terms in the poses, associated with the unknown orientations\n",
    "$\\theta_{i}$. Hence, one solution is to try and solve for the\n",
    "orientations first, and then solve for the translations using linear\n",
    "least squares, exactly as above. This approach is known as **rotation\n",
    "averaging** followed by linear translation recovery. Unfortunately it is\n",
    "sub-optimal as it does not consider the orientation and translation\n",
    "simultaneously. However, it can serve to provide a (very) good initial\n",
    "estimate for nonlinear optimization, discussed below.\n",
    "\n",
    "Indeed, we will prefer to take a second route, which is to use\n",
    "**nonlinear optimization**. As discussed, the error expressions\n",
    "(<a href=\"#eq:logmap\" data-reference-type=\"ref\" data-reference=\"eq:logmap\">[eq:logmap]</a>)\n",
    "are *nonlinear*, and we cannot directly optimize over the poses\n",
    "$T_{i}$. Instead, we will locally linearize the problem and solve\n",
    "the corresponding linear problem using least-squares, and iterate this\n",
    "until convergence. We do this by, at each iteration, parameterizing a\n",
    "pose $T$ by \n",
    "$$\n",
    "T\\approx\\bar{T}\\Delta(\\xi)\n",
    "$$\n",
    "\n",
    "where $\\xi$ are 3D local coordinates\n",
    "$\\xi\\doteq(\\delta x,\\delta y,\\delta\\theta)$ and the incremental pose\n",
    "$\\Delta(\\xi)\\in SE(2)$ is defined as\n",
    "\n",
    "$$\n",
    "\\Delta(\\xi)=\\left[\\begin{array}{cc|c}\n",
    "1 & -\\delta\\theta & \\delta x\\\\\n",
    "\\delta\\theta & 1 & \\delta y\\\\\n",
    "\\hline 0 & 0 & 1\n",
    "\\end{array}\\right]\n",
    "$$\n",
    " which you can recognize as a small angle\n",
    "approximation of the $SE(2)$ matrix\n",
    "(<a href=\"#eq:SE2-matrix\" data-reference-type=\"ref\" data-reference=\"eq:SE2-matrix\">[eq:SE2-matrix]</a>).\n",
    "In 3D the local coordinates $\\xi$ are 6-dimensional, and the small angle\n",
    "approximation is defined as \n",
    "$$\n",
    "\\Delta(\\xi)=\\left[\\begin{array}{ccc|c}\n",
    "1 & -\\delta\\theta_{z} & \\delta\\theta_{y} & \\delta x\\\\\n",
    "\\delta\\theta_{z} & 1 & -\\delta\\theta_{x} & \\delta y\\\\\n",
    "-\\delta\\theta_{y} & \\delta\\theta_{x} & 1 & \\delta z\\\\\n",
    "\\hline 0 & 0 & 0 & 1\n",
    "\\end{array}\\right]\n",
    "$$\n",
    " With this new notation, we can approximate the\n",
    "nonlinear error\n",
    "(<a href=\"#eq:logmap\" data-reference-type=\"ref\" data-reference=\"eq:logmap\">[eq:logmap]</a>)\n",
    "by a linear approximation:\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{1}{2}\\left\\Vert \\log\\left(\\tilde{T}_{ij}^{-1}T_{i}^{-1}T_{j}\\right)\\right\\Vert ^{2}\\approx\\frac{1}{2}\\left\\Vert A_{i}\\xi_{i}+A_{j}\\xi_{j}-b\\right\\Vert ^{2}.\n",
    "$$\n",
    "\n",
    "For $SE(2)$ the matrices $A_{i}$ and $A_{j}$ are the $3\\times3$ **or\n",
    "Jacobian matrices** and $b$ is a $3\\times1$ bias term. The above\n",
    "provides a linear approximation of the term within the norm as a\n",
    "function of the incremental local coordinates $\\xi_{i}$ and $\\xi_{j}$.\n",
    "Deriving the detailed expressions for these Jacobians is beyond the\n",
    "scope of this document, but suffice to say that they exist and not too\n",
    "expensive to compute. In three dimensions, the Jacobian matrices are\n",
    "$6\\times6$ and $16\\times6$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final optimization will—in each iteration—minimize over the local\n",
    "coordinates of all poses by summing over all pose constraints. If we\n",
    "index those constraints by $k$, we have the following least squares\n",
    "problem:\n",
    "\n",
    "$$\n",
    "\\Xi^{*}=\\arg\\min_{\\Xi}\\sum_{k}\\frac{1}{2}\\Vert A_{ki}\\xi_{i}+A_{kj}\\xi_{j}-b_{k}\\Vert ^{2}\n",
    "$$\n",
    "\n",
    "where $\\Xi\\doteq \\{  \\xi_{i}\\}$, the set\n",
    "of all incremental pose coordinates.\n",
    "\n",
    "After solving for the incremental updates $\\Xi$, we update all poses\n",
    "using equation\n",
    "<a href=\"#eq:update\" data-reference-type=\"ref\" data-reference=\"eq:update\">[eq:update]</a>\n",
    "and check for convergence. If the error does not decrease significantly\n",
    "we terminate, otherwise we linearize and solve again, until the error\n",
    "converges. While this is not guaranteed to converge to a global minimum,\n",
    "in practice it does so if there are enough relative measurements and a\n",
    "good initial estimate is available. For example, GPS can provide us with\n",
    "a good initial estimate. However, especially in urban environments GPS\n",
    "can be quite noisy, and it could happen that the map quality suffers by\n",
    "converging to a bad local minimum. Hence, a good quality control process\n",
    "is absolutely necessary in production environments.\n",
    "\n",
    "For SLAM we typically use specializes packages such as G2O, Ceres, or\n",
    "GTSAM that exploit the sparsity of the factor graphs to dramatically\n",
    "speed up computation. Note that MATLAB and/or numpy can solve sparse\n",
    "least squares problems: the specialized SLAM packages simply provide the\n",
    "translation as well as the calculation of the Jacobian matrices above.\n",
    "\n",
    "In summary, the algorithm for nonlinear optimization is\n",
    "\n",
    "-   Start with an initial estimate $\\mathcal{T}^{0}$\n",
    "\n",
    "-   Iterate:\n",
    "\n",
    "    1.  Linearize the factors\n",
    "$\\frac{1}{2}\\Vert \\log(\\tilde{T}_{ij}^{-1}T_{i}^{-1}T_{j})\\Vert ^{2}\\approx\\frac{1}{2}\\Vert A_{i}\\xi_{i}+A_{j}\\xi_{j}-b\\Vert ^{2}$\n",
    "\n",
    "    2.  Solve the least squares problem\n",
    "        $\\Xi^{*}=\\arg\\min_{\\Xi}\\sum_{k}\\frac{1}{2}\\Vert A_{ki}\\xi_{i}+A_{kj}\\xi_{j}-b_{k}\\Vert ^{2}$\n",
    "\n",
    "    3.  Update $X_{i}^{t+1}\\leftarrow X_{j}^{t}\\Delta(\\xi_{i})$\n",
    "\n",
    "-   Until the nonlinear error\n",
    "$J(\\mathcal{T})\\doteq\\sum_{k}\\frac{1}{2}\\Vert \\log(\\tilde{T}_{ij}^{-1}T_{i}^{-1}T_{j})\\Vert ^{2}$\n",
    "    converges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Variable Elimination Algorithm\n",
    "\n",
    "There exists a general algorithm that, given *any* factor graph, can\n",
    "compute the corresponding posterior distribution\n",
    "$p(\\mathcal{X}|\\mathcal{Z})$ on the unknown variables $\\mathcal{X}$.\n",
    "Above we saw that a factor graph represents the unnormalized posterior\n",
    "$\\phi(\\mathcal{X})\\propto P(\\mathcal{X}|\\mathcal{Z})$ as a product of\n",
    "factors, typically generated directly from the measurements. The\n",
    "variable elimination algorithm is a general recipe for converting any\n",
    "factor graph back to a Bayes net, but now *only* on the unknown\n",
    "variables $\\mathcal{X}$.\n",
    "\n",
    "In particular, the **variable elimination** algorithm is a way to\n",
    "factorize any factor graph of the form\n",
    "\n",
    "$$\\phi(\\mathcal{X})=\\phi(X_{1},\\ldots,X_{n})$$ \n",
    "\n",
    "into a factored Bayes net\n",
    "probability density of the form\n",
    "\n",
    "$$p(\\mathcal{X})=p(X_{1}|\\mathcal{S}_{1})p(X_{2}|\\mathcal{S}_{2})\\ldots p(X_{n})=\\prod_{j}p(X_{j}|\\mathcal{S}_{j}),$$\n",
    "\n",
    "where the **separator** $\\mathcal{\\mathcal{S}}(X_{j})$ is defined as the\n",
    "set of variables on which $X_{j}$ is conditioned, after elimination.\n",
    "While this factorization is akin to the chain rule, eliminating a sparse\n",
    "factor graph will typically lead to small separators, although this\n",
    "depends on the chosen variable ordering $X_{1},\\ldots,X_{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable elimination algorithm is listed below,\n",
    "where we again used the shorthand notation\n",
    "$\\Phi_{j:n}\\doteq\\phi(X_{j},\\ldots,X_{n})$ to denote a partially\n",
    "eliminated factor graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Eliminate`($\\Phi_{1:n}$):\n",
    "Given a factor graph on $n$ variables, call `EliminateOne` below for all variables $X_j$, every time yielding a conditional $p(X_{j}|S_{j})$. Return the product of conditionals as the resulting Bayes net:\n",
    "\n",
    "- For $j=1...n$:\n",
    "  - $p(X_{j}|S_{j}),\\Phi_{j+1:n}\\gets \\text{EliminateOne}(\\Phi_{j:n},X_{j})$\n",
    "- return $p(X_{1}|S_{1})p(X_{2}|S_{2})\\ldots p(X_{n})$\n",
    "\n",
    "`EliminateOne`($\\Phi_{j:n},X_{j}$):\n",
    "Eliminate variable $X_{j}$ from a factor graph $\\Phi_{j:n}$:\n",
    "- Remove all factors $\\phi_{i}(\\mathcal{X}_{i})$ that are\n",
    "adjacent to $X_{j}$ \n",
    "- $\\mathcal{S}(X_{j})$ $\\gets$ all variables involved\n",
    "excluding $X_{j}$\n",
    "- $\\psi(X_{j},S_{j})\\gets\\prod_{i}\\phi_{i}(\\mathcal{X}_{i})$\n",
    "- $p(X_{j}|S_{j})\\tau(S_{j})\\gets\\psi(X_{j},S_{j})$\n",
    "- Add the new factor {$\\tau(S_{j})$} back into the graph\n",
    "- return $p(X_{j}|S_{j}),\\Phi_{j+1:n}$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm proceeds by eliminating one\n",
    "variable $X_{j}$ at a time, starting with the complete factor graph\n",
    "$\\Phi_{1:n}$. As we eliminate each variable $X_{j}$, the function\n",
    "produces a single conditional $p(X_{j}|\\mathcal{S}_{j})$, as well as a\n",
    "reduced factor graph $\\Phi_{j+1:n}$ on the remaining variables. After\n",
    "all variables have been eliminated, the algorithm returns the resulting\n",
    "Bayes net with the desired factorization.\n",
    "\n",
    "Above we gave the sum-product version of the variable elimination\n",
    "algorithm. The corresponding max-product version produces a DAG of\n",
    "lookup tables instead, supporting the computation of the MPE. In both\n",
    "cases, the complexity is similar but depends on the chosen variable\n",
    "ordering $X_{1},\\ldots,X_{n}$, as we discuss next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity\n",
    "\n",
    "The elimination algorithm has exponential complexity in the size of the\n",
    "largest separator. The chosen variable ordering $X_{1},\\ldots,X_{n}$ can\n",
    "affect the complexity dramatically. Some orderings lead to smaller\n",
    "separators, and unfortunately it is hard to find an optimal ordering -\n",
    "although it can be done for small graphs. A good heuristic is to\n",
    "greedily eliminate the variables with the smallest separator first.\n",
    "Another is to recursively split the graph, and eliminate starting from\n",
    "the leaves of the binary tree that is formed by the splitting process,\n",
    "but we will not discuss that here.\n",
    "\n",
    "In the special case of HMMs, and in fact any singly connected graph, the\n",
    "complexity is linear in the number of nodes. The reason is easiest to\n",
    "see for an HMM, as after conversion to a factor graph the graph is just\n",
    "a chain. You can easily prove, by induction, that the size of the\n",
    "separator is always one. It must be, by the way, as the resulting DAG is\n",
    "also singly connected (there is at most one path from any node to any\n",
    "other node). Algorithms\n",
    "<a href=\"#alg:max-product-HMM\" data-reference-type=\"ref\" data-reference=\"alg:max-product-HMM\">[alg:max-product-HMM]</a>\n",
    "and\n",
    "<a href=\"#alg:Sum-product-HMM\" data-reference-type=\"ref\" data-reference=\"alg:Sum-product-HMM\">[alg:Sum-product-HMM]</a>\n",
    "are the max-product and sum-product variants that we obtain when\n",
    "eliminating from left to right. However, it is possible to choose a\n",
    "different ordering, even for HMMs. For example, if we eliminate from\n",
    "right to left, we get an equally efficient algorithm, although all the\n",
    "intermediate product and marginal factors will be different.\n",
    "\n",
    "### Exercises\n",
    "\n",
    "1.  Perform symbolic elimination, i.e., just the graph part without\n",
    "    computation, on some factor graphs of interest.\n",
    "\n",
    "2.  Come up with an ordering for an HMM which is neither left-right or\n",
    "    right-left which nevertheless results in a singly-connected Bayes\n",
    "    net.\n",
    "\n",
    "3.  Come up with an ordering to eliminate an HMM which does not lead to\n",
    "    a singly-connected Bayes net.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP Estimation\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://github.com/gtbook/robotics/blob/main/Figures3/hmm-map-X3.png?raw=1\" style=\"width:50.0%\" alt=\"\">\n",
    "<figcaption>\n",
    "<em>X</em><sub>1</sub></span>, respectively: we simply change the elimination order to make sure the variable(s) of interest are eliminated last.\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://github.com/gtbook/robotics/blob/main/Figures3/hmm-map-1.png?raw=1\" style=\"width:50.0%\" alt=\"\">\n",
    "<figcaption>\n",
    "<em>X</em><sub>1</sub></span>, respectively: we simply change the elimination order to make sure the variable(s) of interest are eliminated last.\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Maximum a posteriori estimation is at least as expensive as MPE or\n",
    "calculating the full posterior. Remember that MAP estimation is only\n",
    "interested in a subset of the variables, and we partition the variables\n",
    "into three sets: the variables of interest $\\mathcal{X}$, the nuisance\n",
    "variables $\\mathcal{Y}$, and the observed variables $\\mathcal{Z}$. The\n",
    "elimination algorithm is easy to modify to do MAP estimation, simply *by\n",
    "making sure that the variables of interest $\\mathcal{X}$ are eliminated\n",
    "last*.\n",
    "\n",
    "Why does this work? We can easily see this if we take a “30,000 feet\n",
    "view” of the elimination algorithm. In MAP estimation, we are interested\n",
    "in maximizing $P(\\mathcal{X}|\\mathcal{Z}=\\mathfrak{z})$, but the Bayes\n",
    "net gives us the joint distribution\n",
    "$P(\\mathcal{X},\\mathcal{Y},\\mathcal{Z})$. The first step is to\n",
    "instantiate the evidence $\\mathfrak{z}$and convert to a factor graph\n",
    "$f(\\mathcal{X},\\mathcal{Y};\\mathcal{Z}=\\mathfrak{z})$. When we eliminate\n",
    "using the sum-product algorithm, using the elimination order\n",
    "$\\mathcal{Y},$$\\mathcal{X}$, we obtain a DAG encoding the resulting\n",
    "posterior as\n",
    "$$P(\\mathcal{Y}|\\mathcal{X},\\mathcal{Z}=\\mathfrak{z})P(\\mathcal{X}|\\mathcal{Z}=\\mathfrak{z})$$\n",
    "where $P(\\mathcal{X}|\\mathcal{Z}=\\mathfrak{z})$ is the desired marginal\n",
    "distribution on $\\mathcal{X}$. Using max-product, the resulting DAG for\n",
    "the MPE is\n",
    "$$\\pi(\\mathcal{Y}|\\mathcal{X},\\mathcal{Z}=\\mathfrak{z})\\pi(\\mathcal{X}|\\mathcal{Z}=\\mathfrak{z})$$\n",
    "where the lookup table $\\pi(\\mathcal{X}|\\mathcal{Z}=\\mathfrak{z})$\n",
    "corresponds to the MAP estimate.\n",
    "\n",
    "The higher complexity of MAP estimation derives from the fact that not\n",
    "all elimination orderings are allowed anymore. In particular, the\n",
    "optimal ordering, or even approximately optimal orderings, may all be\n",
    "incompatible with eliminating $\\mathcal{X}$ last."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1.  Do MAP estimation for some factor graphs of interest.\n",
    "\n",
    "2.  Construct a small example where MAP estimation is more expensive\n",
    "    than MPE, even when using optimal orderings for both.\n",
    "\n",
    "3.  Think about the complexity of MAP estimation in an HMM. When is it\n",
    "    not more expensive than MPE?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6OG5ulXzTRe"
   },
   "source": [
    "## Optimization with GTSAM\n",
    "\n",
    "GTSAM exploits sparsity to be computationally efficient. Typically\n",
    "measurements only provide information on the relationship between a\n",
    "handful of variables, and hence the resulting factor graph will be\n",
    "sparsely connected. This is exploited by the algorithms implemented in\n",
    "GTSAM to reduce computational complexity. Even when graphs are too dense\n",
    "to be handled efficiently by direct methods, GTSAM provides iterative\n",
    "methods that are quite efficient regardless.\n",
    "\n",
    "The following code, included in GTSAM as an example, creates the\n",
    "factor graph from Figure\n",
    "<a href=\"#fig:PoseSLAMFG\" data-reference-type=\"ref\" data-reference=\"fig:PoseSLAMFG\">1</a>\n",
    "in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "A6gJFN6lzM3k"
   },
   "outputs": [],
   "source": [
    "graph = gtsam.NonlinearFactorGraph()\n",
    "priorNoise = gtsam.noiseModel.Diagonal.Sigmas((0.3, 0.3, 0.1))\n",
    "graph.add(gtsam.PriorFactorPose2(1, gtsam.Pose2(0, 0, 0), priorNoise))\n",
    "\n",
    "# Create odometry (Between) factors between consecutive poses\n",
    "model = gtsam.noiseModel.Diagonal.Sigmas((0.2, 0.2, 0.1))\n",
    "graph.add(gtsam.BetweenFactorPose2(1, 2, gtsam.Pose2(2, 0, 0), model))\n",
    "graph.add(gtsam.BetweenFactorPose2(2, 3, gtsam.Pose2(2, 0, np.pi/2), model))\n",
    "graph.add(gtsam.BetweenFactorPose2(3, 4, gtsam.Pose2(2, 0, np.pi/2), model))\n",
    "graph.add(gtsam.BetweenFactorPose2(4, 5, gtsam.Pose2(2, 0, np.pi/2), model))\n",
    "\n",
    "# Add the loop closure constraint\n",
    "graph.add(gtsam.BetweenFactorPose2(5, 2, gtsam.Pose2(2, 0, np.pi/2), model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines 1-4 create a nonlinear factor graph and add the unary factor\n",
    "$f_{0}(T_{1})$. As the vehicle travels through the world, it creates\n",
    "binary factors $f_{t}(T_{t},T_{t+1})$ corresponding to odometry,\n",
    "added to the graph in lines 6-12 (Note that M\\_PI\\_2 refers to pi/2).\n",
    "But line 15 models a different event: a **loop closure**. For example,\n",
    "the vehicle might recognize the same location using vision or a laser\n",
    "range finder, and calculate the geometric pose constraint to when it\n",
    "first visited this location. This is illustrated for poses $T_{5}$\n",
    "and $T_{2}$, and generates the (red) loop closing factor\n",
    "$f_{5}(T_{5},T_{2})$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tN-kF1BwpXS"
   },
   "source": [
    "We can optimize this factor graph, by creating an initial estimate of\n",
    "type `gtsam.Values`, and creating and running an optimizer. This is\n",
    "illustrated in the listing below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxyN7AKH0T-7",
    "outputId": "18f5b6c9-e9de-4deb-bc9d-e66cc29b28f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Result:\n",
      "Values with 5 values:\n",
      "Value 1: (gtsam::Pose2)\n",
      "(2.29376924e-21, -4.52805219e-20, -8.15716236e-21)\n",
      "\n",
      "Value 2: (gtsam::Pose2)\n",
      "(2, -8.1719523e-20, -6.25198652e-21)\n",
      "\n",
      "Value 3: (gtsam::Pose2)\n",
      "(4, -3.42174208e-11, 1.57079633)\n",
      "\n",
      "Value 4: (gtsam::Pose2)\n",
      "(4, 2, 3.14159265)\n",
      "\n",
      "Value 5: (gtsam::Pose2)\n",
      "(2, 2, -1.57079633)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the initial estimate\n",
    "initial_estimate = gtsam.Values()\n",
    "initial_estimate.insert(1, gtsam.Pose2(0.5, 0.0, 0.2))\n",
    "initial_estimate.insert(2, gtsam.Pose2(2.3, 0.1, -0.2))\n",
    "initial_estimate.insert(3, gtsam.Pose2(4.1, 0.1, np.pi/2))\n",
    "initial_estimate.insert(4, gtsam.Pose2(4.0, 2.0, np.pi))\n",
    "initial_estimate.insert(5, gtsam.Pose2(2.1, 2.1, -np.pi/2))\n",
    "\n",
    "# Optimize the initial values using a Gauss-Newton nonlinear optimizer\n",
    "optimizer = gtsam.GaussNewtonOptimizer(graph, initial_estimate)\n",
    "result = optimizer.optimize()\n",
    "print(\"Final Result:\\n{}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.50.0 (0)\n -->\n<!-- Pages: 1 -->\n<svg width=\"112pt\" height=\"332pt\"\n viewBox=\"0.00 0.00 112.00 332.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-328 108,-328 108,4 -4,4\"/>\n<!-- var1 -->\n<g id=\"node1\" class=\"node\">\n<title>var1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"77\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"77\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- var2 -->\n<g id=\"node2\" class=\"node\">\n<title>var2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"54\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n</g>\n<!-- var1&#45;&#45;var2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>var1&#45;&#45;var2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71.43,-288.05C67.82,-277.05 63.12,-262.76 59.52,-251.79\"/>\n</g>\n<!-- factor0 -->\n<g id=\"node6\" class=\"node\">\n<title>factor0</title>\n<ellipse fill=\"black\" stroke=\"black\" cx=\"101\" cy=\"-234\" rx=\"1.8\" ry=\"1.8\"/>\n</g>\n<!-- var1&#45;&#45;factor0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>var1&#45;&#45;factor0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M82.81,-288.05C89.25,-269.28 98.96,-240.96 100.72,-235.82\"/>\n</g>\n<!-- var3 -->\n<g id=\"node3\" class=\"node\">\n<title>var3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">3</text>\n</g>\n<!-- var2&#45;&#45;var3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>var2&#45;&#45;var3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M47.6,-216.41C43.36,-205.41 37.81,-191.03 33.54,-179.96\"/>\n</g>\n<!-- var4 -->\n<g id=\"node4\" class=\"node\">\n<title>var4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">4</text>\n</g>\n<!-- var3&#45;&#45;var4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>var3&#45;&#45;var4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-143.7C27,-132.85 27,-118.92 27,-108.1\"/>\n</g>\n<!-- var5 -->\n<g id=\"node5\" class=\"node\">\n<title>var5</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"54\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">5</text>\n</g>\n<!-- var4&#45;&#45;var5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>var4&#45;&#45;var5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M33.4,-72.41C37.64,-61.41 43.19,-47.03 47.46,-35.96\"/>\n</g>\n<!-- var5&#45;&#45;var2 -->\n<g id=\"edge6\" class=\"edge\">\n<title>var5&#45;&#45;var2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M57.65,-36.09C59.68,-46.43 61.98,-59.91 63,-72 67.03,-119.83 67.03,-132.17 63,-180 61.98,-192.09 59.68,-205.57 57.65,-215.91\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<gtbook.display.show at 0x10e8f95e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(graph, result, gtsam.DefaultKeyFormatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oyymz-A0e4D"
   },
   "source": [
    "The result is shown graphically in Figure\n",
    "<a href=\"#fig:example\" data-reference-type=\"ref\" data-reference=\"fig:example\">2</a>,\n",
    "along with covariance ellipses shown in green. These covariance ellipses\n",
    "in 2D indicate the marginal over position, over all possible\n",
    "orientations, and show the area which contain 68.26% of the probability\n",
    "mass (in 1D this would correspond to one standard deviation). The graph\n",
    "shows in a clear manner that the uncertainty on pose $T_{5}$ is now\n",
    "much less than if there would be only odometry measurements. The pose\n",
    "with the highest uncertainty, $T_{4}$, is the one furthest away from\n",
    "the unary constraint $f_{0}(T_{1})$, which is the only factor tying\n",
    "the graph to a global coordinate frame.\n",
    "\n",
    "The figure above was created using an interface that allows you to use\n",
    "GTSAM from within MATLAB, which provides some excellent visualization\n",
    "tools. Similar matplotlib-based visualization tools are available in\n",
    "python.\n",
    "\n",
    "Summary\n",
    "-------\n",
    "\n",
    "We briefly summarize what we learned in this section:\n",
    "\n",
    "1.  LIDAR is a key sensor for autonomous driving\n",
    "\n",
    "2.  Localization can be done with LIDAR, or image-based\n",
    "\n",
    "3.  PoseSLAM: a SLAM variant using ICP pose constraints\n",
    "\n",
    "4.  The PoseSLAM factor graph graphically shows the constraints\n",
    "\n",
    "5.  MAP/MAP solution can be done via nonlinear optimization\n",
    "\n",
    "6.  GTSAM is an easy way to optimize over poses in C++/MATLAB/python"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "S64_driving_perception.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_metadata": {
   "affiliation": "Georgia Institute of Technology",
   "author": "Frank Dellaert and Seth Hutchinson",
   "title": "Introduction to Robotics"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
