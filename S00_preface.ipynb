{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4be934e0",
   "metadata": {},
   "source": [
    "# Preface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "686c700c",
   "metadata": {},
   "source": [
    "<img src=\"Figures1/S10-Robot_menagerie-08.jpg\" alt=\"Splash image with cute robot\" width=\"60%\" align=center style=\"vertical-align:middle;margin:10px 0px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566064b1",
   "metadata": {},
   "source": [
    "# Rationale\n",
    "\n",
    "Since the 1960’s progress in robotics has followed two often independent trajectories. In Engineering Departments, researchers focused on the machine – the design, modeling, and control aspects of robotics. Meanwhile, in AI labs across the world, computer scientists focused on the brain – perception, planning, learning. The chasm between the two was due, in large measure, to the limits of computers. While engineers formulated and solved equations that were easily managed by the computers of the day, computer vision problems required (for the time) enormous memory, and the computational complexity of various planning problems overwhelmed available computation.\n",
    "\n",
    "In recent years, a number of technological advances, both in hardware and in computational paradigms, have allowed these two trajectories to begin to converge into a more unified science of robotics. First, computational hardware (e.g., large-scale memory, general multi-core processors, and GPUs) has finally caught up with computational demands of robotics. Second, several new algorithmic approaches (e.g., graphical models, sampling-based methods, neural networks) have shown remarkable capabilities to solve practical robotics problems. Finally, developing open-source software packages has become a part of the culture of modern robotics research; once a new suite of algorithms has been developed and refined, it typically becomes available to the entire community soon after.\n",
    "In parallel, many robotics technologies have themselves matured to the point that they can now be considered a basic substrate for robotics applications. For example, PID control of individual motors is now well understood; only when systems have significant dynamic effects does control become a real problem. In fact, many modern robotic systems can be considered as purely kinematic devices, with issues related to dynamics and control hidden away in low-level hardware. Engineers solving logistics problems assume that mobile robots can execute basic motion commands, allowing them to ignore dynamic effects. As another example, modern sensors provide extremely rich data sets, and these can be easily handled by modern computers. There is no longer a need for roboticists to worry about how to collect 3D data (LIDAR will do the job), and IMUs can reliably provide information about a robot’s motion through the environment.\n",
    "\n",
    "All of these new developments raise the question, what should a modern roboticist know, and of direct concern here, what material should be included in an introductory robotics class? In 2020, the authors began co-teaching a large introductory robotics course in the College of Computing at Georgia Tech, at a time when both enrollments in computer science and interest in robotics were beginning to explode. The question of what exactly we should be teaching all of these students in the present moment was the impetus for writing the present text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ow_ar2AAFHi0",
   "metadata": {},
   "source": [
    "# Organization of this Book\n",
    "\n",
    "Deciding what material should be included in an introductory robotics text is a kind of constrained optimization problem; the constraints are imposed by the background of the students, space and hardware limitation for large lab courses, and the number of lectures in a semester.\n",
    "\n",
    "In order to meet students “where they are,” we have structured the book as a sequence of chapters that consider increasingly complex robotic systems, allowing us to develop new concepts in the context of a specific robotic system, but such that the system is greatly simplified with respect to all aspects that are not of direct interest at the time.  These chapters are organized as follows:\n",
    "\n",
    "- **Chapter 2**: A trash sorting robot, abstracted to a very high level (that ignores dynamics and geometry) is used to introduce basic concepts from probability theory, statistical estimation theory, and risk analysis. At the conclusion of this chapter, the student will have the basic tools from probability that are needed to address uncertainty and decision making (in the discrete case).\n",
    "- **Chapter 3**: A robot vacuum cleaner, which is also abstracted to a level that ignores geometry and dynamics, is used to introduce more advanced tools from probabilistic inference, including hidden Markov models, Markov decision processes, dynamic Bayes nets, and factor graphs, and these are applied to perception, planning, and reinforcement learning.\n",
    "- **Chapter 4**: A simple mobile robot operating in a warehouse is used to introduce continuous state spaces and continuous random variables. For the first time, geometry is included in the robot’s kinematic description, which includes omni-directional wheels. Several continuous, probabilistic sensor models are introduced. These form the basis for developing Bayesian filtering-based solutions to localization problems (including Markov localization, Monte Carlo localization, and Kalman filtering), and are used to introduce statistical methods for parameter estimation (including MLE, linear regression, and the EM algorithm).\n",
    "- **Chapter 5**: Differential-drive robots (DDRs) are used to introduce the concept of configuration space, and to develop a nonholonomic motion model. Several motion planning models are then introduced (including artificial potential fields, PRMs, and RRTs).  This chapter also introduces the camera as a sensor, and provides a broad introduction to computer vision (including imaging geometry, convolution, and convolutional neural nets). This leads naturally to a description of deep learning (including loss functions, stochastic gradient descent, and transformer architectures).\n",
    "- **Chapter 6**: Self-driving cars motivate the development of SE(2) and LIDAR sensing, which are used to solve the SLAM problem. Data sets from actual vehicle deployment are used to illustrate how LIDAR sensors can be used to solve SLAM problems in real-world applications. The chapter includes an introduction to planning with parameterized motion primitives, and concludes with an introduction to Deep Reinforcement Learning (including Deep Q-learning, policy optimization, and policy gradient methods).\n",
    "- **Chapter 7**: Quadrotors are used to motivate the consideration of dynamics in certain robotics applications. After extending SE(2) to SE(3), the concepts of linear and angular velocity are introduced  (the latter including an introduction to so(3)). These are then employed in the development of a simple dynamic model of quadrotor flight. Motion planning is solved via trajectory optimization. IMUs are introduced, and then, along with cameras, used to solve the visual SLAM problem. The chapter concludes by introducing Neural Radiance Fields (NeRFs) as a way to represent 3D environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01db0ccf",
   "metadata": {},
   "source": [
    "The large number of students in our introductory class (approximately 500 per semester at the time of this writing) makes it impossible to offer any kind of genuine, hands-on hardware experience.  Therefore, we have invested significant effort in developing software that supports the educational goals of the book via realistic simulations, including the use of very large data sets. This aspect of the book is most effectively exploited via its online counterpart, which can be found at [roboticsbook.org](roboticsbook.org).  While the printed text includes code that illustrates concepts in the book, the online version is structured as a set of Jupyter notebooks which can be directly executed by students, allowing them to tinker with parameters and modify algorithms, and then see immediately see the results.\n",
    "The online version also enables integration of large-scale software libraries supporting robotics applications. A prime example is our pervasive use of [GTSAM](gtsam.org), developed at Georgia Tech, which facilitates reasoning and optimization with Bayes nets and factor graphs and is widely used in academia and industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4973e24d",
   "metadata": {},
   "source": [
    "Finally, as is the case for nearly every undergraduate course, the semester is simply too short to cover the entire wish list of topics at uniform depth. This forced us to make difficult decisions about the depth at which certain topics were developed. Our general approach has been to spend more time developing introductory concepts (e.g., Chapter 2 being devoted almost entirely to basic probability theory and statistics), while sometimes hiding the details in code for more advanced topics. The use of GTSAM is an example of the latter.  While we introduce factor graphs and how to solve them at a fairly high level, because GTSAM is deeply integrated into the fabric of the course, we have not gone into much detail about the algorithms that are used in GTSAM, instead opting to demonstrate how to use GTSAM.  We have also included a number of sections that treat advanced material (again, in a somewhat superficial way), and these can be covered at the instructor’s discretion. These sections are indicated by an asterisk in the section heading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b9e59",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "In preparing this book, we gratefully acknowledge the support and contributions of many individuals. We thank our colleagues at Georgia Tech and all the contributors to GTSAM, whose insights were invaluable. Special thanks go to Rowan Crocket and Franklin Koch for their assistance with LaTeX, as well as to the dedicated students and teaching assistants in CS 3630 who helped test our ideas. We also appreciate the encouragement and expertise of the staff at Cambridge University Press—particularly Julie Lancashire—whose guidance inspired this work. Finally, our heartfelt gratitude extends to our families, whose unwavering support made this journey possible."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "S10_introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "latex_metadata": {
   "affiliation": "Georgia Institute of Technology",
   "author": "Frank Dellaert and Seth Hutchinson",
   "title": "Intro to Robotics with GTSAM"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
